# -*- coding: utf-8 -*-
"""DL_hw2_Problem3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XrXA-ivm4RIwGfeyPZLT7kopJcbU7VWq
"""

# torch and torchvision imports
import torch
import torchvision
import torch.nn as nn
import torchvision.transforms as transforms
import torch.optim as optim
import matplotlib.pyplot as plt

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

torch.cuda.is_available()

"""### (a) Plot the training and validation losses and errors as a function of the number of epochs


 The model currently does not achieve less than 12% validation error, you have to tweak the parameters to get it.
"""

# Reading in the dataset
train_transform = transforms.Compose(
    [transforms.RandomHorizontalFlip(),   # Randomly flip the images
    transforms.ColorJitter(brightness=0.2, contrast=0.2), # Color jitter for brightness/contrast
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=train_transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,
                                          shuffle=True)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=16,
                                         shuffle=False)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')


# Defining the model
class View(nn.Module):
    def __init__(self,o):
        super().__init__()
        self.o = o

    def forward(self,x):
        return x.view(-1, self.o)

class allcnn_t(nn.Module):
    def __init__(self, c1=96, c2= 192):
        super().__init__()
        d = 0.5

        def convbn(ci,co,ksz,s=1,pz=0):
            return nn.Sequential(
                nn.Conv2d(ci,co,ksz,stride=s,padding=pz),
                nn.ReLU(True),
                nn.BatchNorm2d(co))

        self.m = nn.Sequential(
            nn.Dropout(0.2),
            convbn(3,c1,3,1,1),
            convbn(c1,c1,3,1,1),
            convbn(c1,c1,3,2,1),
            nn.Dropout(d),
            convbn(c1,c2,3,1,1),
            convbn(c2,c2,3,1,1),
            convbn(c2,c2,3,2,1),
            nn.Dropout(d),
            convbn(c2,c2,3,1,1),
            convbn(c2,c2,3,1,1),
            convbn(c2,10,1,1),
            nn.AvgPool2d(8),
            View(10))

        print('Num parameters: ', sum([p.numel() for p in self.m.parameters()]))

    def forward(self, x):
        return self.m(x)

# The training loop

def train(net, optimizer, criterion, train_loader, test_loader, epochs, model_name, plot):
    model = net.to(device)
    total_step = len(train_loader)
    overall_step = 0
    train_loss_values = []
    train_error = []
    val_loss_values = []
    val_error = []
    for epoch in range(epochs):
        correct = 0
        total = 0
        flag = 0
        running_loss = 0.0

        # Adjust learning rate based on epoch number
        #if epoch < 40:
         #   lr = 0.1
        if epoch < 60:
           lr = 0.01
        else:
           lr = 0.001

        # Update the optimizer with the new learning rate
        #for param_group in optimizer.param_groups:
        #    param_group['lr'] = lr

        if epoch == 25 and flag == 0:
          for op_params in optimizer.param_groups:
            op_params['lr'] = 0.001
          flag = 1
        for i, (images, labels) in enumerate(train_loader):
            # Move tensors to configured device
            images = images.to(device)
            labels = labels.to(device)
            #Forward Pass
            outputs = model(images)
            loss = criterion(outputs, labels)
            optimizer.zero_grad()
            loss.backward()
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            optimizer.step()
            if (i+1) % 1000 == 0:
              print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, total_step, loss.item()))
            if plot:
              info = { ('loss_' + model_name): loss.item() }

              #for tag, value in info.items():
                #logger.scalar_summary(tag, value, overall_step+1)
        train_loss_values.append(running_loss)
        train_error.append(100-100*correct/total)

        model.eval()
        with torch.no_grad():
            correct = 0
            total = 0
            for i, (images, labels) in enumerate(test_loader):
                images = images.to(device)
                labels = labels.to(device)
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        print('Accuracy of the network on the test images: {} %'.format(100 * correct / total))
        val_error.append(100-100*correct/total)
        val_loss_values.append(running_loss)
    return val_error,val_loss_values,train_error,train_loss_values

model = allcnn_t().to(device)
epochs = 50
criterion = nn.CrossEntropyLoss()

# Start with initial learning rate of 0.1
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001, nesterov=True)
val_error, val_loss_values, train_error, train_loss_values = train(model, optimizer, criterion, trainloader, testloader, epochs, 'cnn_curve', True)

"""##### (b) compute the backprop gradient of the loss with respect to the input. Plot this gradient dx for a few input images which the network classifies correctly and also for a few images which the network misclassifies. Comment on the similarities or the differences"""

import numpy as np

# get the true lables of randomly selected images
y = [testset[i][1] for i in range(850, 870)]
labels = [classes[label] for label in y]
labels

#y = [testset[i] for i in range(10,30)]
# Separate images and labels
#y_image = [item[0] for item in y]
#y_label = [item[1] for item in y]

#labels = [classes[label] for label in y_label]
#labels

#_, label = torch.max(model(testset[1001][0].unsqueeze(0).to(device)), 1)
#classes[label]

# get the corresponding predicted lables
image = [testset[i][0].unsqueeze(0) for i in range(850, 870)]  # unsqueeze(0) adds a batch dimension
images = torch.cat(image).to(device)

# Get the predicted class labels (y_bar)
_, y_bar = torch.max(model(images), 1)

for label in y_bar:
    print(classes[label])

# torch.tensor(testset[3][1]).unsqueeze(0).to(device)

#x = torch.tensor(testset[1019][0].unsqueeze(0).to(device))
#model.forward(x)

# x = torch.tensor(testset[1019][0], requires_grad=True).unsqueeze(0).to(device)

# get the gradient for plot (a single data for test)
x = torch.tensor(testset[3][0].unsqueeze(0).to(device), requires_grad=True)
yh = model.forward(x) #testset[1019][0].unsqueeze(0).to(device))
loss = nn.CrossEntropyLoss()

y = torch.tensor(testset[3][1]).unsqueeze(0).to(device)
loss = loss.forward (yh , y)
loss.backward ()

# dx = x.grad.data.clone()
# dx

#Plot the Flatten of 1D array
# test for a single data
import matplotlib.pyplot as plt

# Convert the gradient tensor to a CPU NumPy array
dx = x.grad.data.clone()
dx_np = dx.cpu().detach().numpy()

# Check the shape of dx
print(dx_np.shape)

plt.plot(dx_np.flatten())
plt.title("Gradient Values (dx)")
plt.xlabel("Element Index")
plt.ylabel("Gradient Magnitude")
plt.show()

# get the gradient of all correctly and discorrectly classified images for plot
idx = [3, 17, 107, 858, 1013, 15, 118, 853, 862, 1019]

x = torch.stack([torch.tensor(testset[i][0]) for i in idx]).to(device)
x.requires_grad = True

yh = model.forward(x) #testset[1019][0].unsqueeze(0).to(device))
loss = nn.CrossEntropyLoss()

y = torch.tensor([testset[i][1] for i in idx]).to(device)

loss = loss.forward (yh , y)
loss.backward ()

import seaborn as sns
fig, axes = plt.subplots(2, 5, figsize=(30,30))
axes = axes.flatten()  # Flatten in case of a multi-dimensional axes object
# RGB plot
# Iterate over each sample in the batch (batch size = len(idx))
for i, index in enumerate(idx):
    # Extract gradient for the i-th sample in the batch
    dx_np = x.grad[i].cpu().detach().numpy()
    dx_np = dx_np * 10 # scaling for a clearer plot

    # Check
    print(f"Sample {index} gradient shape:", dx_np.shape)

    # Combine the channels to get the magnitude (for grayscale)
    dx_magnitude = np.sqrt(np.sum(dx_np**2, axis=0))

    # Reshape dx_np to visualize as a color map
    # dx_np = (channels, height, width)
    gradient_image = np.transpose(dx_np, (1, 2, 0))

    #plt.figure()
    #plt.imshow(dx_magnitude) #gradient_image, vmin=0, vmax=0.01) #, cmap='viridis')
    #plt.colorbar()
    #plt.title(f"Gradient Values for Sample {index} (dx) - RGB Colormap")
    #plt.xlabel("Width")
    #plt.ylabel("Height")
    #plt.show()

    ax = axes[i]
    img = ax.imshow(dx_magnitude)
    #ax.set_title(f"Gradient Sample {index}")
    #ax.set_xlabel("Width")
    #ax.set_ylabel("Height")
    fig.colorbar(img, ax=ax, fraction=0.05)

# Adjust layout to prevent overlap
plt.tight_layout()
plt.show()

# plot of original images
# idx = [3, 17, 107, 714, 1013, 15, 112, 118, 711, 1019]

mean = np.array([0.5, 0.5, 0.5])
std = np.array([0.5, 0.5, 0.5])
fig, axes = plt.subplots(1, 10, figsize=(15, 5))

# plot each image
for i, index in enumerate(idx):
    image, label = testset[index]

    image = image.permute(1, 2, 0).numpy()  #  (C, H, W) to (H, W, C) then to numpay array
    image = std * image + mean  # Denormalize
    image = np.clip(image, 0, 1)  # Ensure proper display by clipping values to [0, 1]

    axes[i].imshow(image)
    axes[i].set_title(f"Label: {classes[label]}")
    axes[i].axis('off')

# Adjust
plt.tight_layout()
plt.show()

#3image, label = testset[3]
#mean = np.array([0.5, 0.5, 0.5])
#std = np.array([0.5, 0.5, 0.5])
#image = image.permute(1, 2, 0).numpy()
#image = std * image + mean
#image = np.clip(image, 0, 1)
#plt.imshow(image)
#plt.title(f"Label: {classes[label]}")
#plt.axis('off')

import matplotlib.pyplot as plt
fig, axes = plt.subplots(1, 10, figsize=(30, 5))
# Iterate over each sample in the batch (batch size = len(indices))
for i, index in enumerate(idx):
    # Extract gradient for the i-th sample in the batch
    dx_np = x.grad[i].cpu().detach().numpy()

    # Check the shape of dx to ensure it's correctly processed
    print(f"Sample {index} gradient shape:", dx_np.shape)

    # Plot the gradient as a flattened 1D array
    #plt.figure()
    #plt.plot(dx_np.flatten())
    #plt.title(f"Gradient Values for Sample {index} (dx)")
    #plt.xlabel("Element Index")
    #plt.ylabel("Gradient Magnitude")
    #plt.show()

    ax = axes[i]
    img = ax.plot(dx_np.flatten())
    ax.set_title(f"Gradient Sample {index}")
    ax.set_xlabel("Width")
    ax.set_ylabel("Height")

# Adjust layout to prevent overlap
plt.tight_layout()
plt.show()

"""#### Still(b) For every image in this mini-batch perform the “5-step signed gradient attack”. Plot the loss on the perturbed images as a function of the number of steps in the attack averaged across your mini-batch"""

random_idx = np.random.choice(len(testset), 100, replace=False)
#xs = testset[random_idx][0]
#ys = testset[random_idx][1]

xs = torch.stack([torch.tensor(testset[i][0]) for i in random_idx])
ys = torch.tensor([testset[i][1] for i in random_idx])
xs = xs.to(device)
ys = ys.to(device)

#zip(xs, ys)
#ys

x = torch.tensor(testset[0][0].unsqueeze(0).to(device), requires_grad=True)
y = torch.tensor(testset[0][1]).unsqueeze(0).to(device)

epsilon = 8 / 255.0
step_losses = []

# Perform 5-step signed gradient attack

# forward propagate x through the network
yh = model.forward(x)
loss = nn.CrossEntropyLoss()
loss = loss.forward(yh, y)

# backprop the loss
# model.zero_grad()
loss.backward()

dx = x.grad.data.clone()

x = x + epsilon * dx.sign()

#ell = loss(x, y)
loss.item()

#(toy case) fix an image see the result
x = torch.tensor(testset[3][0].unsqueeze(0).to(device), requires_grad=True)
y = torch.tensor(testset[3][1]).unsqueeze(0).to(device)

epsilon = 8 / 255.0
step_losses = []
loss_list = []
# Perform 5-step signed gradient attack
for k in range(5):
    # forward propagate x through the network
    yh = model.forward(x)
    loss = nn.CrossEntropyLoss()
    loss = loss.forward(yh, y)

    # backprop the loss
    model.zero_grad()
    loss.backward()

    dx = x.grad.data.clone()

    x = x + epsilon * dx.sign()
    x = torch.tensor(x.clamp(0, 1), requires_grad=True)

    #ell = loss(x, y)
    step_losses.append(loss.item())

loss_list.append(step_losses)
# Average the losses across the mini-batch
average_losses = torch.tensor(loss_list).mean(dim=0)

# Plot the average loss as a function of steps
#plt.plot(range(1, 6), average_losses)
#plt.xlabel("Number of Steps")
#plt.ylabel("Average Loss")
#plt.title("Loss on Perturbed Images vs. Number of Steps")
#plt.show()

# for randomly sampled images(mini-batch), see the effect of pertubations
loss_list = []

for i in random_idx:
    x = torch.tensor(testset[i][0].unsqueeze(0).to(device), requires_grad=True)
    y = torch.tensor(testset[i][1]).unsqueeze(0).to(device)
    # print(x)
    epsilon = 8 / 255.0
    step_losses = []
    # Perform 5-step signed gradient attack
    for k in range(5):
        # forward propagate x through the network
        yh = model.forward(x)
        loss = nn.CrossEntropyLoss()
        loss = loss.forward(yh, y)

        # backprop the loss
        model.zero_grad()
        loss.backward()

        dx = x.grad.data.clone()

        x = x + epsilon * dx.sign()
        # x = torch.tensor(x.clamp(0, 1), requires_grad=True)
        x = x.clone().detach().requires_grad_(True)

        step_losses.append(loss.item())

    loss_list.append(step_losses)

# Average the losses across the mini-batch
average_losses = torch.tensor(loss_list).mean(dim=0)

# Plot the average loss as a function of steps
plt.plot(range(1, 6), average_losses)
plt.xlabel("Number of Steps")
plt.ylabel("Average Loss")
plt.title("Loss on Perturbed Images vs. Number of Steps")
plt.show()

"""#### (c) Compute the accuracy of the network on 1-step perturbed images, i.e., for every image in the validation set, perturb the image using a 1-step attack and check the prediction of the network. How does this accuracy on adversarially perturbed images compare with the accuracy on the clean validation set?"""

batch_size = 100
loss_fn = nn.CrossEntropyLoss()


# Function to compute accuracy
def compute_accuracy(model, device, adversarial=False):
    correct = 0
    total = 0

    model.eval()  # Set the model to evaluation mode

    # with torch.no_grad():  # Disable gradient computation
    for i in range(len(testset)):
        xs = torch.tensor(testset[i][0]).unsqueeze(0).to(device) #, requires_grad=True)
        ys = torch.tensor(testset[i][1]).unsqueeze(0).to(device)
        xs, ys = xs.to(device), ys.to(device)

        if adversarial:
            # Perform 1-step signed gradient attack
            xs.requires_grad = True
            yh = model(xs)
            loss_fn = nn.CrossEntropyLoss()
            loss = loss_fn(yh, ys)

            # Backprop to get gradient
            model.zero_grad()
            loss.backward()

            dx = xs.grad.data.clone()
            xs = xs + epsilon * dx.sign()
            xs = xs.clone().detach()
            #xs = torch.tensor(xs, requires_grad=True)

            # xs = torch.tensor(xs.clamp(0, 1), requires_grad=True)

        with torch.no_grad():
            outputs = model(xs)
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == ys).sum().item()
            total += ys.size(0)


    # accuracy
    accuracy = correct / total * 100
    return accuracy

# accuracy on clean images
clean_accuracy = compute_accuracy(model, device, False)
print(f"Accuracy on Clean Images: {clean_accuracy:.2f}%")

# accuracy on 1-step perturbed images
adversarial_accuracy = compute_accuracy(model, device, True)
print(f"Accuracy on 1-Step Perturbed Images: {adversarial_accuracy:.2f}%")